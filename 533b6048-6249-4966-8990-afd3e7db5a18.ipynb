{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review**\n",
    "\n",
    "Hello Matthew!\n",
    "\n",
    "I'm happy to review your project today.\n",
    "  \n",
    "You can find my comments in colored markdown cells:\n",
    "  \n",
    "<div class=\"alert alert-success\">\n",
    "  If everything is done successfully.\n",
    "</div>\n",
    "  \n",
    "<div class=\"alert alert-warning\">\n",
    "  If I have some (optional) suggestions, or questions to think about, or general comments.\n",
    "</div>\n",
    "  \n",
    "<div class=\"alert alert-danger\">\n",
    "  If a section requires some corrections. Work can't be accepted with red comments.\n",
    "</div>\n",
    "  \n",
    "Please don't remove my comments, as it will make further review iterations much harder for me.\n",
    "  \n",
    "Feel free to reply to my comments or ask questions using the following template:\n",
    "  \n",
    "<div class=\"alert alert-info\">\n",
    "  For your comments and questions.\n",
    "</div>\n",
    "  \n",
    "First of all, thank you for turning in the project! You did a pretty good job overall, but there are a few problems that need to be fixed before the project is accepted. Let me know if you have questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Predicting Mobile Plan Selection for Megaline\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Megaline, a major mobile carrier, is aiming to optimize its customer service by recommending new mobile plans to users who are currently on legacy plans. The goal of this project is to develop a machine learning model that can predict which of Megaline's two modern plans—**Smart** or **Ultra**—a customer is most likely to choose based on their behavior.\n",
    "\n",
    "The dataset provided includes information on users who have already switched to one of the two plans. The features include the number of calls made, total call duration, number of text messages sent, and internet data usage for each user in a given month. The target variable indicates which plan the user chose: **Smart** (0) or **Ultra** (1).\n",
    "\n",
    "### Objectives\n",
    "- Preprocess the data to prepare it for machine learning.\n",
    "- Split the data into training, validation, and test sets.\n",
    "- Train and evaluate different machine learning models with the goal of achieving an accuracy of at least **75%**.\n",
    "- Fine-tune hyperparameters to optimize model performance.\n",
    "- Evaluate the model's quality using the test dataset.\n",
    "  \n",
    "By the end of this project, we aim to develop a model that helps Megaline recommend the most suitable plan for its users, improving customer satisfaction and potentially increasing revenue.\n",
    "\n",
    "Let's begin by loading and exploring the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n",
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Project Setup & Data Loading\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "\n",
    "# Display basic info and check for missing values\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fully duplicated rows: 0\n",
      "Empty DataFrame\n",
      "Columns: [calls, minutes, messages, mb_used, is_ultra]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for fully duplicated rows\n",
    "duplicates = df[df.duplicated(keep=False)]  # `keep=False` marks all duplicates\n",
    "\n",
    "# Display duplicated rows\n",
    "print(f'Number of fully duplicated rows: {duplicates.shape[0]}')\n",
    "print(duplicates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Good job!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (2571, 4), (2571,)\n",
      "Validation set: (321, 4), (321,)\n",
      "Test set: (322, 4), (322,)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Split the Data into Training, Validation, and Test Sets\n",
    "\n",
    "# Define features and target variable\n",
    "X = df.drop(columns=['is_ultra'])\n",
    "y = df['is_ultra']\n",
    "\n",
    "# Split data into training (80%), validation (10%), and test (10%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(f'Training set: {X_train.shape}, {y_train.shape}')\n",
    "print(f'Validation set: {X_val.shape}, {y_val.shape}')\n",
    "print(f'Test set: {X_test.shape}, {y_test.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Correct\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Logistic Regression Accuracy: 0.7227\n",
      "Decision Tree Accuracy: 0.8193\n",
      "Random Forest Accuracy (Best Parameters): 0.8349\n",
      "Best Parameters for Random Forest: {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 # Initialize models\n",
    "log_reg = LogisticRegression(random_state=12345)\n",
    "tree_clf = DecisionTreeClassifier(max_depth=5, random_state=12345)\n",
    "rf_clf = RandomForestClassifier(random_state=12345)\n",
    "\n",
    "# Train models\n",
    "log_reg.fit(X_train, y_train)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Hyperparameter tuning for RandomForestClassifier\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_rf_clf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "log_reg_pred = log_reg.predict(X_val)\n",
    "tree_clf_pred = tree_clf.predict(X_val)\n",
    "rf_clf_pred = best_rf_clf.predict(X_val)\n",
    "\n",
    "# Evaluate accuracy\n",
    "log_reg_accuracy = accuracy_score(y_val, log_reg_pred)\n",
    "tree_clf_accuracy = accuracy_score(y_val, tree_clf_pred)\n",
    "rf_clf_accuracy = accuracy_score(y_val, rf_clf_pred)\n",
    "\n",
    "print(f'Logistic Regression Accuracy: {log_reg_accuracy:.4f}')\n",
    "print(f'Decision Tree Accuracy: {tree_clf_accuracy:.4f}')\n",
    "print(f'Random Forest Accuracy (Best Parameters): {rf_clf_accuracy:.4f}')\n",
    "print(f'Best Parameters for Random Forest: {grid_search.best_params_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Everything is correct. Well done! But you need to do two more things:\n",
    "1. Try at least one more model\n",
    "2. Tune hyperparameters at least for one model\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment V2</b>\n",
    "\n",
    "Everything is correct. Good job!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Conclusions: \n",
    "The validation accuracy serves us as an indicator of how well the model is likely to perform on unseen data. \n",
    "\n",
    "In our study, the validation accuracy score of 0.8349 indicates that the model correctly predicts the plan (Smart or Ultra) for about 83.49% of the users in the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7857\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Evaluate the Model on the Test Set\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = tree_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Correct\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with different random state: 0.7857\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Sanity Check\n",
    "\n",
    "# Repeat model training with different random states to sanity check\n",
    "tree_clf_2 = DecisionTreeClassifier(max_depth=5, random_state=10)\n",
    "tree_clf_2.fit(X_train, y_train)\n",
    "y_test_pred_2 = tree_clf_2.predict(X_test)\n",
    "test_accuracy_2 = accuracy_score(y_test, y_test_pred_2)\n",
    "print(f'Test Accuracy with different random state: {test_accuracy_2:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Sanity check is a bit different thing. You need to compare the quality of your best model with the quality of the best constant model. The quality of your model should be at least a bit better than the quality of the constant model. You can take a constant model here: https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html. But it's not necessary to fix it because it is an additional task. You will study this topic in the next sprint.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, we developed a machine learning model to predict which of Megaline's two modern mobile plans—**Smart** or **Ultra**—a user is most likely to choose, based on their monthly behavior. After performing data preprocessing and splitting the data into training, validation, and test sets, we explored several machine learning models.\n",
    "\n",
    "### Key Findings:\n",
    "1. **Data Exploration**:\n",
    "   - The dataset contained key features such as the number of calls, total call duration, number of text messages, and internet data usage, which proved to be important in predicting plan selection.\n",
    "   - We ensured there were no fully duplicated rows or significant issues with missing data, making the dataset suitable for modeling.\n",
    "\n",
    "2. **Model Selection**:\n",
    "   - We experimented with multiple machine learning models, including Decision Trees, Random Forests, and Logistic Regression.\n",
    "   - Hyperparameter tuning was performed using GridSearchCV for the Random Forest model. GridSearchCV evaluated 27 different combinations of hyperparameters using 5-fold cross-validation, resulting in a total of 135 fits. This exhaustive search ensured that the best hyperparameters were selected, improving the model's performance.\n",
    "   - After tuning, the **Random Forest model** showed the best performance with a validation accuracy of **83.49%**, surpassing the project's target accuracy of **75%**.\n",
    "\n",
    "3. **Test Performance**:\n",
    "   - The final model was evaluated on the test set, yielding a similar accuracy score, indicating good generalization capability and robustness.\n",
    "\n",
    "### Conclusion:\n",
    "The Random Forest model, optimized through hyperparameter tuning, successfully identified the important behavioral patterns that influence a user's choice between the **Smart** and **Ultra** plans. The model's accuracy of **83.49%** indicates that it can be reliably used to predict a user’s likely plan, providing Megaline with a valuable tool for improving customer recommendations.\n",
    "\n",
    "The use of GridSearchCV for hyperparameter tuning was instrumental in enhancing the model’s performance. By evaluating numerous hyperparameter combinations, we ensured that the final model was well-tuned and robust, offering greater reliability in predictions.\n",
    "\n",
    "In future iterations, further enhancements could be made by incorporating additional features, such as customer demographics or location, to refine the predictions. Nonetheless, the current model provides a strong foundation for plan recommendation.\n",
    "\n",
    "This concludes the project, and the results demonstrate the potential for machine learning to enhance decision-making in telecommunications.\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2652,
    "start_time": "2024-09-17T13:38:26.550Z"
   },
   {
    "duration": 470,
    "start_time": "2024-09-17T13:41:28.206Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-17T13:43:48.314Z"
   },
   {
    "duration": 230,
    "start_time": "2024-09-17T13:44:39.399Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-17T13:44:58.884Z"
   },
   {
    "duration": 15,
    "start_time": "2024-09-17T13:45:41.126Z"
   },
   {
    "duration": 329,
    "start_time": "2024-09-17T13:46:11.734Z"
   },
   {
    "duration": 18,
    "start_time": "2024-09-17T13:47:35.073Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-17T13:48:01.405Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-17T13:49:25.506Z"
   },
   {
    "duration": 23,
    "start_time": "2024-09-17T13:49:37.348Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-17T13:49:37.750Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-17T13:49:39.005Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-17T13:49:39.895Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-17T13:50:23.304Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-17T13:51:08.070Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-17T13:52:23.117Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-17T15:10:06.839Z"
   },
   {
    "duration": 3106,
    "start_time": "2024-09-17T15:53:27.309Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-17T15:53:30.418Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-17T15:53:30.426Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-17T15:53:30.435Z"
   },
   {
    "duration": 4,
    "start_time": "2024-09-17T15:53:30.447Z"
   },
   {
    "duration": 52,
    "start_time": "2024-09-17T15:53:30.453Z"
   },
   {
    "duration": 378,
    "start_time": "2024-09-17T15:56:49.835Z"
   },
   {
    "duration": 25,
    "start_time": "2024-09-17T15:57:25.231Z"
   },
   {
    "duration": 14,
    "start_time": "2024-09-17T15:57:25.795Z"
   },
   {
    "duration": 8,
    "start_time": "2024-09-17T15:57:26.212Z"
   },
   {
    "duration": 2684,
    "start_time": "2024-09-17T17:14:25.408Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-17T17:14:30.375Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-17T17:14:32.235Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-17T17:14:34.137Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-17T17:14:42.816Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-17T17:14:43.556Z"
   },
   {
    "duration": 23,
    "start_time": "2024-09-17T17:21:48.159Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-17T17:21:50.404Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-17T17:21:52.151Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-17T17:21:55.217Z"
   },
   {
    "duration": 635,
    "start_time": "2024-09-17T17:24:07.477Z"
   },
   {
    "duration": 317,
    "start_time": "2024-09-17T17:24:48.093Z"
   },
   {
    "duration": 321,
    "start_time": "2024-09-17T17:25:48.405Z"
   },
   {
    "duration": 461,
    "start_time": "2024-09-17T17:27:27.874Z"
   },
   {
    "duration": 423,
    "start_time": "2024-09-17T17:27:58.697Z"
   },
   {
    "duration": 25,
    "start_time": "2024-09-17T17:28:25.002Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-17T17:28:25.977Z"
   },
   {
    "duration": 7,
    "start_time": "2024-09-17T17:28:27.707Z"
   },
   {
    "duration": 428,
    "start_time": "2024-09-17T17:28:29.793Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-17T17:28:36.860Z"
   },
   {
    "duration": 11,
    "start_time": "2024-09-17T17:28:43.042Z"
   },
   {
    "duration": 25,
    "start_time": "2024-09-17T17:31:45.901Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-17T17:31:46.807Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-17T17:31:47.725Z"
   },
   {
    "duration": 503,
    "start_time": "2024-09-17T17:31:48.732Z"
   },
   {
    "duration": 22,
    "start_time": "2024-09-17T17:39:54.371Z"
   },
   {
    "duration": 962,
    "start_time": "2024-09-17T17:47:23.345Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-17T17:47:24.309Z"
   },
   {
    "duration": 15,
    "start_time": "2024-09-17T17:47:24.316Z"
   },
   {
    "duration": 767,
    "start_time": "2024-09-17T17:47:24.333Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-17T17:47:25.101Z"
   },
   {
    "duration": 0,
    "start_time": "2024-09-17T17:47:25.103Z"
   },
   {
    "duration": 478,
    "start_time": "2024-09-17T17:48:01.539Z"
   },
   {
    "duration": 960,
    "start_time": "2024-09-17T17:50:18.141Z"
   },
   {
    "duration": 6,
    "start_time": "2024-09-17T17:50:19.104Z"
   },
   {
    "duration": 20,
    "start_time": "2024-09-17T17:50:19.112Z"
   },
   {
    "duration": 34201,
    "start_time": "2024-09-17T17:50:19.134Z"
   },
   {
    "duration": 5,
    "start_time": "2024-09-17T17:50:53.337Z"
   },
   {
    "duration": 10,
    "start_time": "2024-09-17T17:50:53.344Z"
   },
   {
    "duration": 34496,
    "start_time": "2024-09-17T17:51:05.555Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
